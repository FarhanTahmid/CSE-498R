{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports\n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports\n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports\n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports\n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Bengali hate speech .csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate-Non hate distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hate\n",
       "0    20000\n",
       "1    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Hate-Non hate distribution\")\n",
    "df['hate'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hate comments in every category\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "crime                      2000\n",
       "entertainment              1627\n",
       "sports                     1601\n",
       "religion                   1570\n",
       "Meme, TikTok and others    1563\n",
       "politics                    886\n",
       "celebrity                   753\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered=df[df['hate']==1]\n",
    "print(\"Number of hate comments in every category\")\n",
    "df_filtered['category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Cleaning Text</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \n",
       "0                          যত্তসব পাপন শালার ফাজলামী  \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার  \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...  \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়  \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bangla_nlp\n",
    "\n",
    "# remove punctuations\n",
    "df['clean_punctuation']=df['sentence'].apply(bangla_nlp.clean_punctuations)\n",
    "df['clean_emoji']=df['clean_punctuation'].apply(bangla_nlp.clean_emoji)\n",
    "df['clean_text']=df['clean_emoji'].apply(bangla_nlp.clean_url_and_email)\n",
    "df['clean_text']=df['clean_text'].apply(bangla_nlp.clean_digits)\n",
    "drop_columns=['clean_punctuation','clean_emoji']\n",
    "df.drop(columns=drop_columns,inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tokenization</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]  \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_words']=df['clean_text'].apply(bangla_nlp.word_tokenize_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>no_stopword_tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "      <td>[শালা, লুচ্চা, পাঠার, মত, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...</td>\n",
       "      <td>[তুই, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, খেলব...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]   \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]   \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...   \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]   \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...   \n",
       "\n",
       "                         no_stopword_tokenized_words  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1                  [পাপন, শালা, রে, রিমান্ডে, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3                     [শালা, লুচ্চা, পাঠার, মত, যায়]  \n",
       "4  [তুই, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, খেলব...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_stopword_tokenized_words']=df['tokenized_words'].apply(bangla_nlp.remove_stopwords_from_tokens)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (18000,) (18000,)\n",
      "Validation set shape: (6000,) (6000,)\n",
      "Test set shape: (6000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df['no_stopword_tokenized_words']\n",
    "y=df['hate']\n",
    "\n",
    "# Split dataset into training+validation and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split test dataset into validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Check if the dataset needs oversampling or weight change</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with hate 1: 10000\n",
      "Number of rows with hate 0: 20000\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows where 'oh_label' is 1\n",
    "count_label_1 = df[df['hate'] == 1].shape[0]\n",
    "\n",
    "# Count the number of rows where 'oh_label' is 0\n",
    "count_label_0 = df[df['hate'] == 0].shape[0]\n",
    "\n",
    "print(f\"Number of rows with hate 1: {count_label_1}\")\n",
    "print(f\"Number of rows with hate 0: {count_label_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Building</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "csebuetnlp/banglabert does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnormalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize \u001b[38;5;66;03m# pip install git+https://github.com/csebuetnlp/normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModelForPreTraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsebuetnlp/banglabert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsebuetnlp/banglabert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m original_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mআমি কৃতজ্ঞ কারণ আপনি আমার জন্য অনেক কিছু করেছেন।\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\envs\\tf2.7\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\envs\\tf2.7\\lib\\site-packages\\transformers\\modeling_tf_utils.py:2833\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupport for sharded checkpoints using safetensors is coming soon!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m     )\n\u001b[0;32m   2832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_file(pretrained_model_name_or_path, WEIGHTS_NAME, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhas_file_kwargs):\n\u001b[1;32m-> 2833\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2834\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but there is a file for PyTorch weights. Use `from_pt=True` to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2836\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m load this model from those weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2837\u001b[0m     )\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: csebuetnlp/banglabert does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linux_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
