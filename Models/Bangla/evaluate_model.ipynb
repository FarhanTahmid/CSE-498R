{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import bangla_nlp\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bangla Bert model\n",
    "class CyberBullyingClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CyberBullyingClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        probability = self.sigmoid(logits)\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CyberBullyingClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = CyberBullyingClassifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('G:/OneDrive - northsouth.edu/CODES/PROJECTS/PROJECT - Bullishield Models/Created Models/bangla_bert.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports\n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports\n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports\n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports\n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Bengali hate speech .csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate-Non hate distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hate\n",
       "0    20000\n",
       "1    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Hate-Non hate distribution\")\n",
    "df['hate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hate comments in every category\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "crime                      2000\n",
       "entertainment              1627\n",
       "sports                     1601\n",
       "religion                   1570\n",
       "Meme, TikTok and others    1563\n",
       "politics                    886\n",
       "celebrity                   753\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered=df[df['hate']==1]\n",
    "print(\"Number of hate comments in every category\")\n",
    "df_filtered['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \n",
       "0                          যত্তসব পাপন শালার ফাজলামী  \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার  \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...  \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়  \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove punctuations\n",
    "df['clean_punctuation']=df['sentence'].apply(bangla_nlp.clean_punctuations)\n",
    "df['clean_emoji']=df['clean_punctuation'].apply(bangla_nlp.clean_emoji)\n",
    "df['clean_text']=df['clean_emoji'].apply(bangla_nlp.clean_url_and_email)\n",
    "df['clean_text']=df['clean_text'].apply(bangla_nlp.clean_digits)\n",
    "drop_columns=['clean_punctuation','clean_emoji']\n",
    "df.drop(columns=drop_columns,inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]  \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_words']=df['clean_text'].apply(bangla_nlp.word_tokenize_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>no_stopword_tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "      <td>[শালা, লুচ্চা, পাঠার, মত, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...</td>\n",
       "      <td>[তুই, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, খেলব...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]   \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]   \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...   \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]   \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...   \n",
       "\n",
       "                         no_stopword_tokenized_words  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1                  [পাপন, শালা, রে, রিমান্ডে, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3                     [শালা, লুচ্চা, পাঠার, মত, যায়]  \n",
       "4  [তুই, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, খেলব...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_stopword_tokenized_words']=df['tokenized_words'].apply(bangla_nlp.remove_stopwords_from_tokens)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>no_stopword_tokenized_words</th>\n",
       "      <th>clean_string_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, দরকার]</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে দরকার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ একটা দে...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "      <td>[শালা, লুচ্চা, পাঠার, মত, যায়]</td>\n",
       "      <td>শালা লুচ্চা পাঠার মত যায়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...</td>\n",
       "      <td>[তুই, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, খেলব...</td>\n",
       "      <td>তুই শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]   \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]   \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...   \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]   \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, ...   \n",
       "\n",
       "                         no_stopword_tokenized_words  \\\n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]   \n",
       "1                  [পাপন, শালা, রে, রিমান্ডে, দরকার]   \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...   \n",
       "3                     [শালা, লুচ্চা, পাঠার, মত, যায়]   \n",
       "4  [তুই, শালা, গাজা, খাইছচ, তুর, মার, হেডায়, খেলব...   \n",
       "\n",
       "                                  clean_string_words  \n",
       "0                          যত্তসব পাপন শালার ফাজলামী  \n",
       "1                        পাপন শালা রে রিমান্ডে দরকার  \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ একটা দে...  \n",
       "3                           শালা লুচ্চা পাঠার মত যায়  \n",
       "4      তুই শালা গাজা খাইছচ তুর মার হেডায় খেলবে সাকিব  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_string_words']=df['no_stopword_tokenized_words'].apply(' '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "    tokenized_texts = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokenized_texts\n",
    "\n",
    "max_length=128\n",
    "\n",
    "train_tokenized_texts = tokenize_texts(train_data['clean_string_words'].tolist(), max_length)\n",
    "test_tokenized_texts = tokenize_texts(train_data['clean_string_words'].tolist(), max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test inputs and labels\n",
    "train_inputs = {\n",
    "    'input_ids': train_tokenized_texts['input_ids'],\n",
    "    'attention_mask': train_tokenized_texts['attention_mask']\n",
    "}\n",
    "\n",
    "train_labels = torch.tensor(train_data['hate'].values,dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "test_inputs = {\n",
    "    'input_ids': test_tokenized_texts['input_ids'],\n",
    "    'attention_mask': test_tokenized_texts['attention_mask']\n",
    "}\n",
    "\n",
    "test_labels = torch.tensor(test_data['hate'].values,dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 8.79 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_inputs, test_labels, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {key: val\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m test_inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m test_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m (outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     11\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(labels\u001b[38;5;241m.\u001b[39mcpu(), predictions\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mCyberBullyingClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[0;32m     13\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1073\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1071\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m-> 1073\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1082\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:211\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_ids)\n\u001b[1;32m--> 211\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_type_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT - Bullishield Models\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.79 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_inputs, test_labels, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {key: val.to(device) for key, val in test_inputs.items()}\n",
    "        labels = test_labels.to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "    \n",
    "    accuracy = accuracy_score(labels.cpu(), predictions.cpu())\n",
    "    precision = precision_score(labels.cpu(), predictions.cpu())\n",
    "    recall = recall_score(labels.cpu(), predictions.cpu())\n",
    "    f1 = f1_score(labels.cpu(), predictions.cpu())\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_inputs, test_labels, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
