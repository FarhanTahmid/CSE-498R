{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import easyocr\n",
    "import regex\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import bangla_nlp\n",
    "import english_nlp\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reader = easyocr.Reader(['en','bn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='Example Images/bengali-2.PNG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the image. Filepath: Example Images/bengali-2.PNG\n",
      "Text: শুয়োরের বাচ্চা তোকে একবার পেয়ে নেই খালি] দেখেনিব একদম], Probability: 0.2587815690071471\n",
      "Bangla Texts: ['শুয়োরের বাচ্চা তোকে একবার পেয়ে নেই খালি] দেখেনিব একদম]']\n",
      "English Texts: []\n"
     ]
    }
   ],
   "source": [
    "file=Path(filepath)\n",
    "if file.is_file():\n",
    "    print(f\"Got the image. Filepath: {filepath}\")\n",
    "    result_from_text = text_reader.readtext(filepath)\n",
    "    full_text=[]\n",
    "    english_texts=[]\n",
    "    bangla_texts=[]\n",
    "    for (bbox, text, prob) in result_from_text:\n",
    "        print(f'Text: {text}, Probability: {prob}')\n",
    "        if(bool(regex.fullmatch(r'\\P{L}*\\p{Bengali}+(?:\\P{L}+\\p{Bengali}+)*\\P{L}*', text))):\n",
    "            full_text.append(text + \"। \")\n",
    "            bangla_texts.append(text)\n",
    "        else:\n",
    "            full_text.append(text+\". \")\n",
    "            english_texts.append(text)\n",
    "    print(f\"Bangla Texts: {bangla_texts}\")\n",
    "    print(f\"English Texts: {english_texts}\")   \n",
    "        \n",
    "else:\n",
    "    print(\"There was no image found with the filepath\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bangla Bert model\n",
    "class CyberBullyingClassifierBangla(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CyberBullyingClassifierBangla, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        probability = self.sigmoid(logits)\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model\n",
    "class CyberBullyingClassifierEnglish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CyberBullyingClassifierEnglish, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        probability = self.sigmoid(logits)\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CyberBullyingClassifierBangla(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bangla_model=CyberBullyingClassifierBangla()\n",
    "bangla_model.to(device=device)\n",
    "bangla_model.load_state_dict(torch.load('Created Models/bangla_bert.pth'))\n",
    "bangla_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CyberBullyingClassifierEnglish(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_model=CyberBullyingClassifierEnglish()\n",
    "english_model.to(device=device)\n",
    "english_model.load_state_dict(torch.load('Created Models/english_bert.pth'))\n",
    "english_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bangla_string_preprocessing(string):\n",
    "    clean_punctuation=bangla_nlp.clean_punctuations(text=string)\n",
    "    clean_emoji=bangla_nlp.clean_emoji(text=clean_punctuation)\n",
    "    clean_url=bangla_nlp.clean_url_and_email(clean_emoji)\n",
    "    clean_text=bangla_nlp.clean_digits(text=clean_url)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_string_preprocessing(text):\n",
    "    clean_emoji=english_nlp.remove_emoji(text)\n",
    "    clean_punctuation=clean_emoji.translate(str.maketrans('', '', string.punctuation))\n",
    "    clean_url=english_nlp.remove_urls(clean_punctuation)\n",
    "    clean_text=english_nlp.remove_numbers(clean_url)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bangla_cyberbullying(model, texts, device):\n",
    "    tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "    model.eval()\n",
    "    clean_texts=[]\n",
    "    for i in texts:\n",
    "        clean_texts.append(bangla_string_preprocessing(i))\n",
    "    tokenized_texts = tokenizer.batch_encode_plus(\n",
    "        clean_texts,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    inputs = {key: val.to(device) for key, val in tokenized_texts.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probabilities = outputs.cpu().numpy()\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_english_cyberbullying(model, texts, device):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "    model.eval()\n",
    "    clean_texts=[]\n",
    "    for i in texts:\n",
    "        clean_texts.append(english_string_preprocessing(i))\n",
    "    tokenized_texts = tokenizer.batch_encode_plus(\n",
    "        clean_texts,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    inputs = {key: val.to(device) for key, val in tokenized_texts.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probabilities = outputs.cpu().numpy()\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkCyberBullying(full_text,english_texts,bangla_texts):\n",
    "    custom_probabilities=None\n",
    "    # check if there are any bangla or english texts in the list. if there are, pass them to respective models\n",
    "    if(len(english_texts)>0):\n",
    "        # Predict cyberBullying for english texts\n",
    "        custom_probabilities = predict_bangla_cyberbullying(english_model, english_texts, device)\n",
    "    if(len(bangla_texts)>0):\n",
    "        # Predict cyberBullying for bangla texts\n",
    "        custom_probabilities = predict_bangla_cyberbullying(bangla_model, full_text, device)   \n",
    "\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    custom_pred_labels = [1 if prob >= 0.5 else 0 for prob in custom_probabilities]\n",
    "\n",
    "    # Print predictions\n",
    "    for text, label in zip(full_text, custom_pred_labels):\n",
    "        if label == 1:\n",
    "            print(f'Text: \"{text}\" is predicted as cyberbullying.')\n",
    "        else:\n",
    "            print(f'Text: \"{text}\" is predicted as not cyberbullying.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \"শুয়োরের বাচ্চা তোকে একবার পেয়ে নেই খালি] দেখেনিব একদম]। \" is predicted as cyberbullying.\n"
     ]
    }
   ],
   "source": [
    "checkCyberBullying(full_text=full_text,english_texts=english_texts,bangla_texts=bangla_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
